name: XWP Automation - Change-Driven Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      execution_mode:
        description: 'Test execution mode'
        required: true
        default: 'change-driven'
        type: choice
        options:
          - 'change-driven'
          - 'run-all'
          - 'run-specific'
      specific_tests:
        description: 'Specific tests/folders to run (only used with "run-specific" mode) - excludes                       <div class="card">
                          <h2>üîß Test Coverage</h2>
                          <p>‚úì Post Creation & Editing</p>
                          <p>‚úì Publishing Workflow</p>
                          <p>‚úì Tags & Metadata</p>
                          <p>‚úì Content Verification</p>
                          <p>‚úì Dashboard & Navigation</p>
                          <p>‚úì Categories Management</p>
                          <p>‚úì All Posts Integration</p>tests'
        required: false
        default: 'tests/dashboard.spec.ts'
        type: string
      browser_matrix:
        description: 'Browser coverage'
        required: false
        default: 'chromium-only'
        type: choice
        options:
          - 'chromium-only'
          - 'cross-browser'
      target_branch:
        description: 'Target branch to test (for E2E mode)'
        required: false
        default: 'main'
        type: string
      include_login_test:
        description: 'Include authentication setup test'
        required: false
        default: false
        type: boolean

jobs:
  detect-changes:
    name: üîç Analyze Changes & Plan Tests
    runs-on: ubuntu-latest
    outputs:
      changed-files: ${{ steps.changes.outputs.files }}
      test-strategy: ${{ steps.strategy.outputs.strategy }}
      tests-to-run: ${{ steps.strategy.outputs.tests }}
      skip-tests: ${{ steps.strategy.outputs.skip }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Get changed files
        id: changes
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            CHANGED_FILES=$(git diff --name-only ${{ github.event.pull_request.base.sha }}..${{ github.event.pull_request.head.sha }})
          else
            CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD)
          fi
          
          echo "files<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: üß† Determine Test Strategy
        id: strategy
        run: |
          CHANGED_FILES="${{ steps.changes.outputs.files }}"
          TESTS_TO_RUN=""
          STRATEGY="targeted"
          SKIP_TESTS="false"
          EXECUTION_MODE="${{ github.event.inputs.execution_mode || 'change-driven' }}"
          
          echo "üìÅ Changed files:"
          echo "$CHANGED_FILES"
          echo "üéØ Execution mode: $EXECUTION_MODE"
          echo ""
          
          # Handle manual workflow dispatch modes
          if [ "$EXECUTION_MODE" = "run-all" ]; then
            echo "üöÄ Manual: Run all tests requested"
            TESTS_TO_RUN="all"
            STRATEGY="manual-full"
          elif [ "$EXECUTION_MODE" = "run-specific" ]; then
            SPECIFIC_TESTS="${{ github.event.inputs.specific_tests }}"
            echo "üéØ Manual: Run specific tests - $SPECIFIC_TESTS"
            
            # Filter out login tests - they should only run via authentication setup
            FILTERED_TESTS=$(echo "$SPECIFIC_TESTS" | sed 's/tests-excluded\/login\.spec\.ts//g' | sed 's/login\.spec\.ts//g' | sed 's/  */ /g' | sed 's/^ *//g' | sed 's/ *$//g')
            
            if [ "$FILTERED_TESTS" != "$SPECIFIC_TESTS" ]; then
              echo "üö´ Login tests removed from manual execution - use 'include_login_test' option instead"
            fi
            
            if [ -z "$FILTERED_TESTS" ] || [ "$FILTERED_TESTS" = " " ]; then
              echo "‚ö†Ô∏è No valid tests specified after filtering - defaulting to dashboard test"
              TESTS_TO_RUN="tests/dashboard.spec.ts"
            else
              TESTS_TO_RUN="$FILTERED_TESTS"
            fi
            STRATEGY="manual-specific"
          elif [ "$EXECUTION_MODE" = "change-driven" ]; then
            # Original change-driven logic
            
            # Skip if only documentation changes
            if echo "$CHANGED_FILES" | grep -qE '\.(md|txt|json)$' && ! echo "$CHANGED_FILES" | grep -qvE '\.(md|txt|json)$'; then
              echo "üìù Only documentation changes detected - skipping tests"
              SKIP_TESTS="true"
              STRATEGY="skip"
            else
              echo "üîç Analyzing changed files for test impact..."
              
              # Check for page object changes
              if echo "$CHANGED_FILES" | grep -q "pages/.*\.ts"; then
                CHANGED_PAGES=$(echo "$CHANGED_FILES" | grep "pages/.*\.ts" | sed 's/pages\///g' | sed 's/\.ts//g')
                echo "üìÑ Page objects changed: $CHANGED_PAGES"
                
                for page in $CHANGED_PAGES; do
                  case $page in
                    "login.page"|"base.page")
                      echo "üîê Login page changes detected - authentication setup will be triggered"
                      ;;
                    "dashboard.page")
                      TESTS_TO_RUN="$TESTS_TO_RUN tests/dashboard.spec.ts"
                      ;;
                    "categories.page")
                      TESTS_TO_RUN="$TESTS_TO_RUN tests/categories.spec.ts"
                      ;;
                    "all-posts.page")
                      TESTS_TO_RUN="$TESTS_TO_RUN tests/all-posts.spec.ts"
                      ;;
                    "post.page")
                      TESTS_TO_RUN="$TESTS_TO_RUN tests/post-creation.spec.ts"
                      ;;
                    "page.factory")
                      TESTS_TO_RUN="$TESTS_TO_RUN tests/dashboard.spec.ts tests/categories.spec.ts"
                      ;;
                  esac
                done
              fi
              
              # Check for utility changes
              if echo "$CHANGED_FILES" | grep -q "utils/.*\.ts"; then
                CHANGED_UTILS=$(echo "$CHANGED_FILES" | grep "utils/.*\.ts")
                echo "üîß Utilities changed: $CHANGED_UTILS"
                
                if echo "$CHANGED_UTILS" | grep -q "element.helper\|test.utils\|environment.utils"; then
                  echo "üö® Core utilities changed - running all tests"
                  TESTS_TO_RUN="all"
                  STRATEGY="full"
                elif echo "$CHANGED_UTILS" | grep -q "smart-logger\|error-inspector\|ai-test-healer"; then
                  echo "üß† AI/Logging utilities changed - running smoke tests"
                  TESTS_TO_RUN="tests/dashboard.spec.ts"
                  STRATEGY="smoke"
                fi
              fi
              
              # Check for fixture/data changes
              if echo "$CHANGED_FILES" | grep -q "fixtures/.*\.ts"; then
                echo "üìä Test data changed - running related tests"
                if echo "$CHANGED_FILES" | grep -q "login-data"; then
                  echo "üîê Login data changes detected - authentication setup will be triggered"
                fi
                if echo "$CHANGED_FILES" | grep -q "dashboard-data"; then
                  TESTS_TO_RUN="$TESTS_TO_RUN tests/dashboard.spec.ts"
                fi
              fi
              
              # Check for configuration changes
              if echo "$CHANGED_FILES" | grep -qE "(playwright\.config|tsconfig|package\.json|\.env)"; then
                echo "‚öôÔ∏è Configuration changed - running smoke tests"
                TESTS_TO_RUN="tests/dashboard.spec.ts"
                STRATEGY="config"
              fi
              
              # Check for test file changes
              if echo "$CHANGED_FILES" | grep -q "tests/.*\.spec\.ts"; then
                CHANGED_TESTS=$(echo "$CHANGED_FILES" | grep "tests/.*\.spec\.ts")
                echo "üß™ Test files changed: $CHANGED_TESTS"
                TESTS_TO_RUN="$TESTS_TO_RUN $CHANGED_TESTS"
              fi
              
              # If no specific tests identified, run smoke tests
              if [ -z "$TESTS_TO_RUN" ] && [ "$SKIP_TESTS" = "false" ]; then
                echo "üîç No specific test mapping found - running smoke tests"
                TESTS_TO_RUN="tests/dashboard.spec.ts"
                STRATEGY="smoke"
              fi
            fi
          fi
          
          # Clean up test list
          TESTS_TO_RUN=$(echo "$TESTS_TO_RUN" | tr ' ' '\n' | sort -u | tr '\n' ' ' | sed 's/[[:space:]]*$//')
          
          echo "üéØ Test Strategy: $STRATEGY"
          echo "üß™ Tests to run: $TESTS_TO_RUN"
          echo "‚è≠Ô∏è Skip tests: $SKIP_TESTS"
          
          echo "strategy=$STRATEGY" >> $GITHUB_OUTPUT
          echo "tests=$TESTS_TO_RUN" >> $GITHUB_OUTPUT
          echo "skip=$SKIP_TESTS" >> $GITHUB_OUTPUT

  run-tests-with-auth:
    name: üß™ Execute Tests (with Auth Setup)
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.skip-tests != 'true'
    strategy:
      matrix:
        browser: ${{ github.event.inputs.browser_matrix == 'cross-browser' && fromJSON('["chromium", "firefox", "webkit"]') || fromJSON('["chromium"]') }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.target_branch || github.ref }}
      - uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Setup dependencies
        run: |
          npm ci
          npx playwright install ${{ matrix.browser }} --with-deps

      - name: üîê Run authentication setup (always)
        run: |
          # Create temporary config for login test
          cat > playwright.config.temp.ts << 'EOF'
          import { defineConfig, devices } from '@playwright/test';
          import { config } from 'dotenv';
          config();
          export default defineConfig({
            testDir: './tests-excluded',
            fullyParallel: true,
            forbidOnly: !!process.env.CI,
            retries: process.env.CI ? 2 : 0,
            workers: 1,
            reporter: 'html',
            use: {
              baseURL: process.env.STAGING_BASE_URL || 'https://staging.go.ione.nyc',
              trace: 'on-first-retry',
              screenshot: 'only-on-failure',
            },
            projects: [{ name: 'chromium', use: { ...devices['Desktop Chrome'] } }],
          });
          EOF
          
          cat > .env << 'EOF'
          STAGING_BASE_URL=${{ secrets.STAGING_BASE_URL || 'https://staging.go.ione.nyc' }}
          STAGING_API_URL=${{ secrets.STAGING_API_URL || 'https://staging.go.ione.nyc/wp-json' }}
          STAGING_LOGIN_URL=${{ secrets.STAGING_BASE_URL || 'https://staging.go.ione.nyc' }}/wp-login.php?skip_sso
          ADMIN_USERNAME=${{ secrets.ADMIN_USERNAME }}
          ADMIN_PASSWORD=${{ secrets.ADMIN_PASSWORD }}
          EOF
          
          # Run login test to create authentication state
          echo "üîê Running authentication setup..."
          npx playwright test login.spec.ts --config=playwright.config.temp.ts --project=chromium
          rm -f playwright.config.temp.ts .env
          
          if [ -f "playwright/.auth/staging-ione.json" ]; then
            echo "‚úÖ Authentication state created successfully"
          else
            echo "‚ùå Authentication state not created"
          fi

      - name: üéØ Run targeted tests
        run: |
          # Check if authentication state is available
          AUTH_STATE=""
          if [ -f "playwright/.auth/staging-ione.json" ]; then
            AUTH_STATE="storageState: 'playwright/.auth/staging-ione.json',"
            echo "‚úÖ Using authentication state for tests"
          else
            echo "‚è≠Ô∏è Running tests without authentication state"
          fi
          
          # Create config for main tests
          cat > playwright.config.temp.ts << EOF
          import { defineConfig, devices } from '@playwright/test';
          import { config } from 'dotenv';
          config();
          export default defineConfig({
            testDir: './tests',
            fullyParallel: true,
            forbidOnly: !!process.env.CI,
            retries: process.env.CI ? 2 : 0,
            workers: 1,
            reporter: 'html',
            use: {
              baseURL: process.env.STAGING_BASE_URL || 'https://staging.go.ione.nyc',
              trace: 'on-first-retry',
              screenshot: 'only-on-failure',
              ${AUTH_STATE}
            },
            projects: [{ name: '${{ matrix.browser }}', use: { ...devices['Desktop Chrome'] } }],
          });
          EOF
          
          cat > .env << 'EOF'
          STAGING_BASE_URL=${{ secrets.STAGING_BASE_URL || 'https://staging.go.ione.nyc' }}
          STAGING_API_URL=${{ secrets.STAGING_API_URL || 'https://staging.go.ione.nyc/wp-json' }}
          STAGING_LOGIN_URL=${{ secrets.STAGING_BASE_URL || 'https://staging.go.ione.nyc' }}/wp-login.php?skip_sso
          ADMIN_USERNAME=${{ secrets.ADMIN_USERNAME }}
          ADMIN_PASSWORD=${{ secrets.ADMIN_PASSWORD }}
          EOF
          
          # Run tests
          TESTS="${{ needs.detect-changes.outputs.tests-to-run }}"
          if [ "$TESTS" = "all" ]; then
            echo "üöÄ Running full test suite"
            npx playwright test --config=playwright.config.temp.ts --project=${{ matrix.browser }}
          else
            echo "üéØ Running targeted tests: $TESTS"
            npx playwright test $TESTS --config=playwright.config.temp.ts --project=${{ matrix.browser }}
          fi
          
          # Cleanup all temporary files
          rm -f playwright.config.temp.ts .env
          rm -f playwright/.auth/staging-ione.json

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.browser }}
          path: |
            test-results/
            playwright-report/
          retention-days: 3

  # New job to publish reports to GitHub Pages
  publish-report:
    name: üìä Publish Test Report
    runs-on: ubuntu-latest
    needs: run-tests-with-auth
    if: always() && github.ref == 'refs/heads/main'
    permissions:
      contents: write
      pages: write
      id-token: write
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-*
          merge-multiple: true
          path: ./all-results
      
      - name: Create consolidated report
        run: |
          mkdir -p ./docs/reports/latest
          
          # Copy the latest playwright-report if it exists
          if [ -d "./all-results/playwright-report" ]; then
            cp -r ./all-results/playwright-report/* ./docs/reports/latest/
          fi
          
          # Generate timestamp and short commit hash
          CURRENT_TIME=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
          SHORT_COMMIT=$(echo "${{ github.sha }}" | cut -c1-7)
          
          # Extract test results from artifacts
          TOTAL_TESTS=0
          PASSED_TESTS=0
          FAILED_TESTS=0
          
          # Parse test results from test-results directory
          if [ -d "./all-results/test-results" ]; then
            # Count JSON result files which indicate individual test runs
            TOTAL_TESTS=$(find ./all-results/test-results -name "*results.json" | wc -l | tr -d ' ')
            PASSED_TESTS=$(find ./all-results/test-results -name "*results.json" -exec grep -l '"status":"passed"' {} \; | wc -l | tr -d ' ')
            FAILED_TESTS=$(find ./all-results/test-results -name "*results.json" -exec grep -l '"status":"failed"' {} \; | wc -l | tr -d ' ')
          fi
          
          # Fallback to counting from playwright report if available
          if [ $TOTAL_TESTS -eq 0 ] && [ -f "./all-results/playwright-report/index.html" ]; then
            # Try to extract numbers from HTML report
            TOTAL_TESTS=$(grep -o '[0-9]\+ passed' ./all-results/playwright-report/index.html | head -1 | grep -o '[0-9]\+' || echo "0")
            PASSED_TESTS=$TOTAL_TESTS
          fi
          
          # Default fallback values if no results found
          if [ $TOTAL_TESTS -eq 0 ]; then
            TOTAL_TESTS="Unknown"
            PASSED_TESTS="Unknown"
            SUCCESS_RATE="N/A"
            ACHIEVEMENT_MSG="Test results not available in artifacts"
            STATUS_CLASS="warning"
          else
            SUCCESS_RATE=$(echo "scale=0; $PASSED_TESTS * 100 / $TOTAL_TESTS" | bc -l)
            if [ $PASSED_TESTS -eq $TOTAL_TESTS ]; then
              ACHIEVEMENT_MSG="üéâ ${SUCCESS_RATE}% Success Rate Achieved! All $TOTAL_TESTS tests passing perfectly"
              STATUS_CLASS="success"
            else
              ACHIEVEMENT_MSG="‚ö†Ô∏è ${SUCCESS_RATE}% Success Rate - $PASSED_TESTS of $TOTAL_TESTS tests passing"
              STATUS_CLASS="warning"
            fi
          fi
          
          echo "üìä Test Results Summary:"
          echo "Total Tests: $TOTAL_TESTS"
          echo "Passed Tests: $PASSED_TESTS"
          echo "Failed Tests: $FAILED_TESTS"
          echo "Success Rate: $SUCCESS_RATE%"
          
          # Update the main dashboard with latest run info
          cat > ./docs/index.html << EOF
          <!DOCTYPE html>
          <html lang="en">
          <head>
              <meta charset="UTF-8">
              <meta name="viewport" content="width=device-width, initial-scale=1.0">
              <title>XWP Automation - Test Report Dashboard</title>
              <style>
                  * { margin: 0; padding: 0; box-sizing: border-box; }
                  body {
                      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
                      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                      min-height: 100vh;
                      color: #333;
                  }
                  .container {
                      max-width: 1200px;
                      margin: 0 auto;
                      padding: 40px 20px;
                  }
                  .header {
                      text-align: center;
                      color: white;
                      margin-bottom: 40px;
                  }
                  .header h1 {
                      font-size: 3rem;
                      margin-bottom: 10px;
                      text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
                  }
                  .achievement {
                      color: white;
                      text-align: center;
                      border-radius: 15px;
                      padding: 30px;
                      margin-bottom: 30px;
                      box-shadow: 0 10px 30px rgba(0,0,0,0.3);
                  }
                  .achievement.success {
                      background: linear-gradient(135deg, #38a169, #68d391);
                  }
                  .achievement.warning {
                      background: linear-gradient(135deg, #d69e2e, #f6e05e);
                  }
                  .achievement.error {
                      background: linear-gradient(135deg, #e53e3e, #feb2b2);
                  }
                  .dashboard {
                      display: grid;
                      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
                      gap: 30px;
                      margin-bottom: 40px;
                  }
                  .card {
                      background: white;
                      border-radius: 15px;
                      padding: 30px;
                      box-shadow: 0 10px 30px rgba(0,0,0,0.2);
                  }
                  .actions {
                      display: grid;
                      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                      gap: 20px;
                  }
                  .action-btn {
                      display: block;
                      background: white;
                      color: #4a5568;
                      text-decoration: none;
                      padding: 20px;
                      border-radius: 10px;
                      text-align: center;
                      font-weight: 600;
                      box-shadow: 0 5px 15px rgba(0,0,0,0.1);
                      transition: all 0.3s ease;
                  }
                  .action-btn:hover {
                      transform: translateY(-2px);
                      box-shadow: 0 10px 25px rgba(0,0,0,0.2);
                  }
                  .timestamp {
                      text-align: center;
                      color: white;
                      opacity: 0.8;
                      margin-top: 30px;
                  }
              </style>
          </head>
          <body>
              <div class="container">
                  <div class="header">
                      <h1>üé≠ XWP Automation</h1>
                      <p>WordPress E2E Testing Dashboard</p>
                  </div>
                  
                  <div class="achievement ${STATUS_CLASS}">
                      <h2>${ACHIEVEMENT_MSG}</h2>
                  </div>
                  
                  <div class="dashboard">
                      <div class="card">
                          <h2>üìä Latest Results</h2>
                          <p><strong>‚úÖ ${PASSED_TESTS}/${TOTAL_TESTS} Tests Passing</strong></p>
                          <p><strong>üéØ ${SUCCESS_RATE}% Success Rate</strong></p>
                          <p><strong>‚ö° Fast & Reliable</strong></p>
                      </div>
                      <div class="card">
                          <h2>ÔøΩ Test Coverage</h2>
                          <p>‚úì Post Creation & Editing</p>
                          <p>‚úì Publishing Workflow</p>
                          <p>‚úì Tags & Metadata</p>
                          <p>‚úì Content Verification</p>
                      </div>
                  </div>
                  
                  <div class="actions">
                      <a href="./reports/latest/index.html" class="action-btn">üìä View Detailed Report</a>
                      <a href="https://github.com/zahraakhalili20/xwp-automation" class="action-btn">ÔøΩ Source Code</a>
                      <a href="https://github.com/zahraakhalili20/xwp-automation/actions" class="action-btn">üîÑ CI/CD Pipeline</a>
                  </div>
                  
                  <div class="timestamp">
                      Last updated: ${CURRENT_TIME}<br>
                      Build: #${{ github.run_number }} | Commit: ${SHORT_COMMIT}
                  </div>
              </div>
          </body>
          </html>
          EOF
      
      - name: Commit and push reports
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add docs/
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update test reports - $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
            git push
            echo "‚úÖ Reports committed and pushed to repository"
          fi
      
      - name: Setup Pages (if enabled)
        uses: actions/configure-pages@v4
        continue-on-error: true
      
      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./docs
        continue-on-error: true
      
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
        continue-on-error: true